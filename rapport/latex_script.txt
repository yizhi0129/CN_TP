\documentclass{article}
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\usepackage{graphicx} % Required for inserting images
\usepackage{fancyhdr}
\usepackage{geometry}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage[french]{babel}

\title{Calcul Numérique TP}
\author{YANG Yizhi}

\begin{document}
\maketitle

\tableofcontents

\newpage
\section{Introduction : Problème Poisson 1D}

On s'intéresse au problème du Poisson à dimension 1. Le problème de Poisson 1D est un système des équations aux dérivées partielles couramment rencontrée en mathématiques appliquées, en physique et en ingénierie. Dans le monde de physique macroscopique, tous les problèmes sont continus dans l'espace réel, et pourtant, dans le monde de l'informatique, la discrétisation est toujours nécessaire.
\\

On applique le maillage uniforme, c'est-à-dire sur le même axe, on prend des ponits équidistants, et à chaque point on aura une équation de dérivées partielles de second degré par rapport à une condition locale. Pendant les cours de TD précédents, on a écrit le système de ces équations en forme matricielle tridiagonale. Donc résoudre ce problème est équivalent à résoudre l'équation du produit matriciel $Ax = b$. Par une simplification de condition des seconds menbres, on sait que la solution analytique est sous forme linéaire $T(x) = T_0 + x(T_1 - T_0)$.
\\

Dans la suite de ce TP, on va d'abord introduire ce problème et puis proposer des méthodes afin d'approximer la solution, qui sera comparée avec la solution exacte.

\section{Test d'environnement}

En créant une image dans Docker Container, on configure l'environnement du travail pour que les bibliothèques CBLAS et LAPACK soient reconnues lors de la compilation. Un fichier de test a été créé et le résultat se donne :

\begin{verbatim}
The exponantial value is e = 2.718282 
The maximum single precision value from values.h is maxfloat = 3.402823e+38 
The maximum single precision value from float.h is flt_max = 3.402823e+38 
The maximum double precision value from float.h is dbl_max = 1.797693e+308 
The epsilon in single precision value from float.h is flt_epsilon = 1.192093e-07 
The epsilon in double precision value from float.h is dbl_epsilon = 2.220446e-16 

Test of ATLAS (BLAS/LAPACK) environment 
x[0] = 1.000000, y[0] = 6.000000
x[1] = 2.000000, y[1] = 7.000000
x[2] = 3.000000, y[2] = 8.000000
x[3] = 4.000000, y[3] = 9.000000
x[4] = 5.000000, y[4] = 10.000000

Test DCOPY y <- x 
y[0] = 1.000000
y[1] = 2.000000
y[2] = 3.000000
y[3] = 4.000000
y[4] = 5.000000
\end{verbatim}

\newpage
\section{Méthode directe}
\subsection{Stockage Bande}

\subsubsection{Déclaration et allocation en C}

En effet, on doit déclarer et allouer les matrices de manière à ce qu'elles soient compatibles avec les fonctions BLAS/LAPACK, donc de forme General Band ici. C'est une forme efficace pour les matrices multidiagonales, car la plupart de leur éléments sont nuls. Au lieu d'occuper une mémoire de taille $n*n$, il suffira de $lab*n$, avec $lab$ le nombre des diagonales.

\subsubsection{la Constante \texttt{LAPACK\_COL\_MAJOR}}

Cette constante signifie que la matrice donnée est stockée colonne par colonne. Afin de convertir les indices usuels, il faut définir la fonction suivante :

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}

\begin{lstlisting}[language=C, caption=General Band Indices]
// i, j from 0 to *la -1
int indexABCol(int i, int j, int *lab)
{
  return (j + 1) * (*lab - 1) + i - 1;
}
\end{lstlisting}

\subsubsection{la Dimension Principale}

Cela signifie la largeur de la bande stockée, i.e. le nombre total des diagonales (la diagonale principale, les subdiagonales et sousdiagonales).

\subsection{Explication des Fonctions BLAS/LAPACK}
\subsubsection{dgbmv}

C'est une fonction BLAS qui effectue une multiplication d'une matrice (stockée en bande) par un vecteur. La lettre "d" signifie que les éléments contenus dans les matrices sont de type double. 


\subsubsection{dgbtrf}

C'est une routine LAPACK qui effectue la factorisation LU d'une matrice générale stockée en bande, donc les éléments sont de type double.

\subsubsection{dgbtrs}

C'est une routine LAPACK qui résout un système d'équations linéaires pour une matrice stockée en bande après une factorisation LU. Ses éléments sont de type double.

\subsubsection{dgbsv}

C'est similaire de dgbtrs mais avec pivotage partiel, qui est une combinaision de $dgbtrf$ et $dgbtrs$.

\subsubsection{Calcul de la norme du résidu relatif}

La norme du résidu relatif s'écrit sous la forme : 

\[\|r\|_2 = \frac{\|Ax - b\|_2}{\|b\|_2}\]

On applique d'abord la fonction $cblas\_dgbmv$ pour calculer le produit matrice-vecteur $Ax$, puis on effectue l'addition de deux vecteurs $Ax$ et $b$ par la fonction $cblas\_daxpy$.

On pourra utiliser la fonction $cblas\_dnrm2$ pour calculer la norme euclidienne.

\subsubsection{Méthode de validation}

Pour la solution du système $Ax = b$, on pourra comparer l'erreur relative de $x$ par rapport à la solution exacte $x_{exact}$ : \[\|err\|_2 = \frac{\|x - e_{exact}\|_2}{\|x_{exact}\|_2}\]

On pourra aussi utiliser le résidu relatif, cela donne un ordre de grandeur $10^{-16}$ :
\begin{verbatim}
The relative forward error is relres = 2.393518e-16
\end{verbatim}

Pour la factorisation LU, on pourra calculer $\|A - LU\|_2$, si cette valeur est très petit, on peut dire que la méthode est validée.

\subsubsection{Performance et complexité}

On rajoute une mesure de temps pour les méthodes différentes en utilisant l'entête <time.h> et les fonctions suivantes : 
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}

\begin{lstlisting}[language=C, caption=Time Measure]
clock_t start_timer, end_timer;
double elapsed_time;
start_timer = clock();
// code to calculate solution
end_timer = clock();
elapsed_time = (double)(end_timer - start_timer) / (double)CLOCKS_PER_SEC;
printf("Elapsed time for direct method: %lf seconds\n", elapsed_time);
\end{lstlisting}

La méthode avec $LU$ factorisation $dgbtrf$ puis $dgbtrs$ donne :
\begin{verbatim}
Elapsed time for direct method: 0.000823 seconds
\end{verbatim}
La méthode direct $dgbsv$ donne :
\begin{verbatim}
Elapsed time for direct method: 0.000909 seconds
\end{verbatim}

Complexité : $gdbtrf$ admet une complexité $O(n^3)$ pour la factorisation LU, $dgbtrs$ entre $O(n^2)$ et $O(n^3)$; pour $dgbsv$, il faut $O(n)$ pour la factorisation LU et $O(n)$ pour résoudre le système. (avec $n$ la taille de matrice)

\section{Méthodes itératives}
Pour la méthode alpha-Richardson, on calcule le facteur $\alpha$ en utilisant les valeurs propres de la matrice du Poisson 1D : \[\alpha = \frac{2}{max(eigval) + min(eigval)}\]

Pour la méthode Jacobi (respectivement Gauss-Seidel), on calcule d'abord la matrice $M = D$ (respectivement $M = D - E$), ensuite l'inverse de matrice $M^{-1}$. Par itération, on calcule $x^{k+1} = x^k + M^{-1}r^k$ avec le résidu $r^k = b - Ax$.

\begin{figure}[!h]
\centering
\includegraphics[width=0.25\linewidth]{cvg_alpha.png}
\caption{\label{fig:Alpha-Richardson Iteration Convergence}Alpha-Richardson Iteration Convergence}
\end{figure}

\begin{figure}[!h]
\centering
\includegraphics[width=0.25\linewidth]{cvg_J.png}
\caption{\label{fig:Jacobi Iteration Convergence}Jacobi Iteration Convergence}
\end{figure}

\begin{figure}[!h]
\centering
\includegraphics[width=0.25\linewidth]{cvg_GS.png}
\caption{\label{fig:Gauss-Seidel Iteration Convergence}Gauss-Seidel Iteration Convergence}
\end{figure}


Comme la valeur $alpha\_opt = 0.5$ et $D^{-1} = 0.5I_n$, la méthode alpha-Richardson et la méthode Jacobi sont équivalentes :
\begin{verbatim}
Optimal alpha for simple Richardson iteration is : 0.500000
The relative forward error is relres = 5.093853e-03
Elapsed time for iterative methods: 0.000867 s
\end{verbatim}
Elles partagent aussi la même vitesse de convergence, la méthode de Gauss-Seidel converge deux fois plus vite que celles-ci.

\section{Stockage CSR et CSC}
Pour la méthode CSR (Compressed Sparse Row), on stocke les valeurs significatives, les indices de colonnes et les pointeurs de lignes de la matrice ciblée dans trois tableaux unidimensionnels. Ici un algorithme possible pour la matrice tridiagonale du Poisson 1D :

\begin{algorithm}
  \caption{MatriceTridiagonaleVersCSR}
  \KwData{matrice}
  \KwResult{values, columns, row\_ptr}

  \BlankLine
  \tcp{Initialisation des tableaux}
  values $\leftarrow$ [] \tcp*{Tableau pour les valeurs non nulles}
  columns $\leftarrow$ [] \tcp*{Tableau pour les indices de colonnes}
  row\_ptr $\leftarrow$ [] \tcp*{Tableau pour les pointeurs de lignes}

  \BlankLine
  \For{chaque ligne i de la matrice}{
    \BlankLine
    \tcp{Parcourir les éléments de la ligne}
    \For{chaque élément j de la ligne i}{
      \BlankLine
      \If{j est sur la diagonale principale}{
        Ajouter $A[i, j]$ à values\;
        Ajouter $j$ à columns\;
      }
      \ElseIf{j est sur la diagonale supérieure ou inférieure}{
        Ajouter $A[i, j]$ à values\;
        Ajouter $j$ à columns\;
      }
    }
    \BlankLine
    \tcp{Ajouter la taille actuelle de values à row\_ptr}
    Ajouter la taille actuelle de values à row\_ptr\;
  }

  \BlankLine
  \Return values, columns, row\_ptr\;
  
\end{algorithm}

Similairement, pour un stockage CSC (Compressed Sparse Column), il faut just inverser les rôles de lignes et colonnes.

\section{Conclusion}

La convergence plus rapide de Gauss-Seidel par rapport à Jacobi dans le contexte spécifique du problème de Poisson 1D avec une matrice tridiagonale peut être attribuée à la nature séquentielle de la mise à jour, qui peut mieux exploiter la structure de la matrice et conduire à une convergence plus rapide.
\\

Le choix entre le stockage en format général band (GB), Compressed Sparse Row (CSR), et Compressed Sparse Column (CSC) dépend des caractéristiques spécifiques de la matrice et des opérations que l'on a l'intention de réaliser. Le format GB est plus convenable pour les matrices tridiagonales et il donne un accès efficace aux éléments adjacents dans la bande; les formats CSR et CSC sont plus convenables pour les matrices creuses, car ils ne nécessitent pas un stockage pour les zéros, mais ils ont un surcoût pour accéder aux éléments dans le même colonne (pour CSR) ou la même ligne (pour CSC).

\end{document}